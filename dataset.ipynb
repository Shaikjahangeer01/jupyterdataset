{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c38b64e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\nayeemuddin\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: chardet in c:\\users\\nayeemuddin\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\nayeemuddin\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nayeemuddin\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\nayeemuddin\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nayeemuddin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas chardet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141c2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4eeead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing the CSV files\n",
    "folder_path = r\"C:\\Users\\Nayeemuddin\\Desktop\\Property_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349056a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 CSV files.\n"
     ]
    }
   ],
   "source": [
    "# List all files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Check the files\n",
    "print(f\"Found {len(csv_files)} CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e393d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Load each CSV file into a DataFrame\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "final_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041fda18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (14532, 23)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with all NaN values\n",
    "final_dataframe.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "# Standardize column names (optional)\n",
    "final_dataframe.columns = final_dataframe.columns.str.strip().str.lower()\n",
    "\n",
    "# Display the shape of the combined DataFrame\n",
    "print(f\"Final DataFrame shape: {final_dataframe.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5fca7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save as a CSV file\n",
    "final_dataframe.to_csv(r\"C:\\Users\\Nayeemuddin\\Desktop\\CombinedPropertyData.csv\", index=False)\n",
    "\n",
    "print(\"Combined DataFrame saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "194c7471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of the combined data: (14532, 21)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path containing the CSV files\n",
    "folder_path = r\"C:\\Users\\Nayeemuddin\\Desktop\\Property_data-20250109T055028Z-001\"  # Replace with the correct folder path\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through and read each file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')  # Adjust encoding if needed\n",
    "        dataframes.append(df)\n",
    "    except UnicodeDecodeError:\n",
    "        # Try an alternative encoding if UTF-8 fails\n",
    "        df = pd.read_csv(file_path, encoding='latin1')\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Combine all DataFrames\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Drop invalid columns (e.g., based on a threshold for missing values)\n",
    "threshold = 0.5  # Exclude columns with more than 50% missing values\n",
    "valid_columns = combined_df.columns[combined_df.isnull().mean() < threshold]\n",
    "combined_df = combined_df[valid_columns]\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "output_file = r\"C:\\Users\\Nayeemuddin\\Desktop\\CombinedPropertyData.csv\"  # Adjust as needed\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Get the final shape of the combined DataFrame\n",
    "final_shape = combined_df.shape\n",
    "\n",
    "print(\"Final shape of the combined data:\", final_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7653d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'location' column is missing in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path containing the CSV files\n",
    "folder_path = r\"C:\\Users\\Nayeemuddin\\Desktop\\Property_data-20250109T055028Z-001\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Check if there are CSV files in the folder\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in the folder:\", folder_path)\n",
    "else:\n",
    "    # List to store DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through and read each file\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path, encoding='utf-8')  # Adjust encoding if needed\n",
    "            dataframes.append(df)\n",
    "        except UnicodeDecodeError:\n",
    "            # Try an alternative encoding if UTF-8 fails\n",
    "            df = pd.read_csv(file_path, encoding='latin1')\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Drop invalid columns (e.g., based on a threshold for missing values)\n",
    "    threshold = 0.5  # Exclude columns with more than 50% missing values\n",
    "    valid_columns = combined_df.columns[combined_df.isnull().mean() < threshold]\n",
    "    combined_df = combined_df[valid_columns]\n",
    "\n",
    "    # Ensure 'location' column exists in the combined dataset\n",
    "    if 'location' not in combined_df.columns:\n",
    "        print(\"The 'location' column is missing in the dataset.\")\n",
    "    else:\n",
    "        # Calculate the percentage of properties in HSR Layout\n",
    "        total_properties = len(combined_df)\n",
    "        hsr_properties = combined_df['location'].str.contains(\"HSR Layout\", case=False, na=False).sum()\n",
    "        percentage_hsr = (hsr_properties / total_properties) * 100\n",
    "\n",
    "        # Print the rounded percentage\n",
    "        print(f\"Percentage of properties in HSR Layout: {round(percentage_hsr)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb017b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The required 'location' or 'rent' column is missing in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path containing the CSV files\n",
    "folder_path = r\"C:\\Users\\Nayeemuddin\\Desktop\\Property_data-20250109T055028Z-001\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Check if there are CSV files in the folder\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in the folder:\", folder_path)\n",
    "else:\n",
    "    # List to store DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through and read each file\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path, encoding='utf-8')  # Adjust encoding if needed\n",
    "            dataframes.append(df)\n",
    "        except UnicodeDecodeError:\n",
    "            # Try an alternative encoding if UTF-8 fails\n",
    "            df = pd.read_csv(file_path, encoding='latin1')\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Drop invalid columns (e.g., based on a threshold for missing values)\n",
    "    threshold = 0.5  # Exclude columns with more than 50% missing values\n",
    "    valid_columns = combined_df.columns[combined_df.isnull().mean() < threshold]\n",
    "    combined_df = combined_df[valid_columns]\n",
    "\n",
    "    # Ensure 'location' and 'rent' columns exist in the combined dataset\n",
    "    if 'location' not in combined_df.columns or 'rent' not in combined_df.columns:\n",
    "        print(\"The required 'location' or 'rent' column is missing in the dataset.\")\n",
    "    else:\n",
    "        # Convert rent column to numeric (handle any errors in conversion)\n",
    "        combined_df['rent'] = pd.to_numeric(combined_df['rent'], errors='coerce')\n",
    "\n",
    "        # Remove rows where 'rent' is NaN or invalid\n",
    "        combined_df = combined_df.dropna(subset=['location', 'rent'])\n",
    "\n",
    "        # Group by locality and calculate average rent\n",
    "        avg_rent_per_locality = combined_df.groupby('location')['rent'].mean()\n",
    "\n",
    "        # Find the locality with the highest average rent\n",
    "        highest_avg_rent_locality = avg_rent_per_locality.idxmax()\n",
    "        highest_avg_rent_value = avg_rent_per_locality.max()\n",
    "\n",
    "        # Print the result\n",
    "        print(f\"Locality with the highest average rent: {highest_avg_rent_locality}\")\n",
    "        print(f\"Highest average rent: {highest_avg_rent_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b54bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
